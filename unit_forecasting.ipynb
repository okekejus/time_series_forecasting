{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "corporations = pd.read_excel(\"data/All_Corps_and_VotingUnits.xlsx\", index_col=\"Date\").iloc[:,3:10]\n",
    "corporations.columns = [\"name\", \"email\", \"status\", \"CAO\", \"CMRAO\", \"account_id2\", \"voting_units\"]\n",
    "corporations = corporations.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Units \n",
    "plt.figure(figsize = (20,6))\n",
    "plt.plot(corporations['voting_units'])\n",
    "plt.title(\"Distriution of Daily Unit Counts\")\n",
    "plt.ylabel(\"Total Voting Units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e45ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a lot of meaningful data before 1965\n",
    "corporations = corporations[(corporations.index > dt.datetime(1967,1,1)) & (corporations.index <= dt.datetime(2025,11,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Units - including filter\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.plot(corporations['voting_units'])\n",
    "plt.title(\"Distriution of Daily Unit Counts\")\n",
    "plt.ylabel(\"Total Voting Units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e63aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling data, going with monthly aggregations for predicitions \n",
    "\n",
    "resampled_df = corporations.resample('ME').sum(numeric_only=True)\n",
    "#resampled_df = resampled_df.fillna(0)\n",
    "window_size = 40\n",
    "resampled_df['units_smoothed'] = resampled_df['voting_units'].rolling(window=window_size).mean() # smoothed/moving average\n",
    "resampled_df['units_smoothed_sd'] = resampled_df['voting_units'].rolling(window=window_size).std() # smoothed/moving sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting things to look at the nature of the data \n",
    "plt.figure(figsize=(20,6))\n",
    "sns.lineplot(data=resampled_df, x = resampled_df.index, y='voting_units', label = \"Resampled Monthly Sum\")\n",
    "sns.lineplot(data=resampled_df, x = resampled_df.index, y='units_smoothed', label = \"Moving Average\")\n",
    "sns.lineplot(data=resampled_df, x = resampled_df.index, y='units_smoothed_sd', label = \"Moving Std. Deviation\")\n",
    "plt.xlabel(\"Registration Date\")\n",
    "plt.ylabel(\"Total Voting Units\")\n",
    "plt.title(\"Total Units, Moving Average/Std. Dev Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance is not constant, neither is the mean\n",
    "# dataset is likely not stationary. Will confirm this using dickey fuller test \n",
    "result = adfuller(resampled_df['voting_units'].dropna())\n",
    "print('ADF:', result[0])\n",
    "print('p:', result[1])\n",
    "print('Critical Values:', result[4])\n",
    "if result[1] <= 0.05: print(\"The dataset is stationary\") \n",
    "else: print(\"The dataset is not stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a720d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying Seasonality Trends\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.title(\"STL Trend\")\n",
    "res = STL(resampled_df['voting_units'].dropna(), period=12).fit()\n",
    "res.resid.plot()\n",
    "\n",
    "# there are no seasonality trends (clear, repeating patterns in the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f49591",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df['vu_log'] = np.log1p(resampled_df['voting_units'].dropna()) # stabilizing the variance of the dataset \n",
    "resampled_df['vu_diff'] = resampled_df.vu_log.diff().dropna()\n",
    "resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset should be stationary after log transform and differencing \n",
    "result = adfuller(resampled_df['vu_diff'].dropna())\n",
    "print('ADF:', result[0])\n",
    "print('p:', result[1])\n",
    "print('Critical Values:', result[4])\n",
    "if result[1] <= 0.05: print(\"The dataset is stationary\") \n",
    "else: print(\"The dataset is not stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68032a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = resampled_df.vu_diff.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ACF plot (autocorrelation)\n",
    "plot_acf(time_series, ax=axes[0], lags=40)\n",
    "axes[0].set_title('ACF Plot')\n",
    "\n",
    "# PACF plot (partial autocorrelation)\n",
    "plot_pacf(time_series, ax=axes[1], lags=40, method='ywm')\n",
    "axes[1].set_title('PACF Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae085295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF has big negative spike at lag 1, which is a signature of an MA(1) proces. \n",
    "# PACF is telling us strong neg spike at lag 1, matches AR(1) or AR(2) pattern. Not as strongly \n",
    "# combined, AIRMA 0, 1,1 seems like the most natural model \n",
    "# ACF and PACF have a dominant lag-1 effect, but the ACF has clean sharp spike \n",
    "# differencing was needed, noise is MA(1) \n",
    "# no seasonality needs to beincluded "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e2078",
   "metadata": {},
   "source": [
    "# ARIMA(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(time_series, order=(0,1,1))\n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "# terrible, terrible model as ther eis a lot of volatility in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a3c82",
   "metadata": {},
   "source": [
    "# GARCH(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "garch = arch_model(time_series, vol='GARCH', p=1, q=1, mean='Zero')\n",
    "garch_results = garch.fit()\n",
    "print(garch_results.summary())\n",
    "# not as great, but we are getting there "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1105e8",
   "metadata": {},
   "source": [
    "# ARIMA(0,1,1) + GARCH(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335202d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA(0,1,1) first\n",
    "arima_model = ARIMA(resampled_df[\"voting_units\"].dropna(), order=(0,1,1))\n",
    "arima_res = arima_model.fit()\n",
    "\n",
    "# Get ARIMA residuals to feed into GARCH\n",
    "arima_resid = arima_res.resid.dropna()\n",
    "\n",
    "# Fit GARCH on ARIMA residuals\n",
    "garch = arch_model(arima_resid, vol='GARCH', p=1, q=1, mean='Zero')\n",
    "garch_res = garch.fit()\n",
    "\n",
    "print(garch_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_res.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aef4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(resampled_df['voting_units'].dropna(), seasonal=False, stepwise=True) # also an option for less volatile data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ad655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "\n",
    "models = {\n",
    "    \"arima\": arima_model,\n",
    "    \"garch\": garch_res\n",
    "}\n",
    "\n",
    "with open(\"arima_garch_bundle.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
